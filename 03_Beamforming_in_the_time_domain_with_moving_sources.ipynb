{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acoular as ac\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"./custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30472242-7ab5-4bf8-ad11-5004edd855c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "# for the purpose of readability, we will move the functions for the animations,\n",
    "# the necessary imports, and the method to generate synthetic data to the beginning of the notebook\n",
    "import acoular as ac\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "\n",
    "def init_animation_fixed_focus(rg, micgeom, trs, lz, col):\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': '3d'}, num=1)\n",
    "    ax.set(xlabel='x', ylabel='y', zlabel='z')\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(-6, 6)\n",
    "    ax.set_zlim(0, lz)\n",
    "    # Plot microphone positions\n",
    "    ax.scatter(micgeom.pos[0], micgeom.pos[1], micgeom.pos[2], 'o', label='mics')\n",
    "    # Plot static grid elements\n",
    "    gpos = rg.pos.reshape((3, rg.nxsteps, rg.nysteps))\n",
    "    ax.plot_wireframe(gpos[0], gpos[1], gpos[2], color='k', lw=0.2, label='grid')\n",
    "    # Initialize scatter plots for sources\n",
    "    scatter_plots = [\n",
    "        ax.scatter([], [], [], label=f'source {i}', color=col[i]) for i in range(len(trs))\n",
    "    ]\n",
    "    fig.legend()\n",
    "    plt.close(fig)  # Close figure to prevent extra display in notebooks\n",
    "    return fig, ax, scatter_plots\n",
    "\n",
    "def update_frame_fixed_focus(frame, scatter_plots, trs, t_pass, ax):\n",
    "    ttime = frame * (t_pass / 100)\n",
    "    # Update scatter plots\n",
    "    for i, tr in enumerate(trs):\n",
    "        loc = tr.location(ttime)\n",
    "        scatter_plots[i]._offsets3d = (\n",
    "            [loc[0]],\n",
    "            [loc[1]],\n",
    "            [loc[2]]\n",
    "        )\n",
    "    # Update dynamic title with current time\n",
    "    ax.set_title(f't = {ttime:.2f}s')\n",
    "    return scatter_plots \n",
    "\n",
    "def init_animation_moving_focus(rgm, tr0, trs, micgeom, t_pass, lz, col):\n",
    "    # Create figure and 3D axes\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': '3d'}, num=1)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(-6, 6)\n",
    "    ax.set_zlim(0, lz)\n",
    "    state={}\n",
    "    # Plot microphone positions\n",
    "    ax.scatter(micgeom.pos[0], micgeom.pos[1], micgeom.pos[2], 'o', label='mics')\n",
    "    # At t=0, compute the grid's global coordinates and plot as wireframe.\n",
    "    gpos = rgm.pos.reshape((3, rgm.nxsteps, rgm.nysteps)) + np.array(tr0.location(0))[:, None, None]\n",
    "    state['grid_wire'] = ax.plot_wireframe(gpos[0], gpos[1], gpos[2],\n",
    "                                  color='k', lw=0.2, label='grid')\n",
    "    # Initialize scatter plots for sources\n",
    "    state['scatter_plots'] = [\n",
    "        ax.scatter([], [], [], label=f'source {i}', color=col[i]) for i in range(len(trs))\n",
    "    ]\n",
    "    fig.legend()\n",
    "    plt.close(fig)  # Prevent immediate display in notebooks\n",
    "    return fig, ax, state\n",
    "\n",
    "def update_frame_moving_focus(frame, state, rgm, tr0, trs, col, ax):\n",
    "    ttime = frame * (t_pass / 100)\n",
    "    # Update grid wireframe\n",
    "    new_gpos = rgm.pos.reshape((3, rgm.nxsteps, rgm.nysteps)) + np.array(tr0.location(ttime))[:, None, None]\n",
    "    # Remove the old grid wireframe lines\n",
    "    if isinstance(state['grid_wire'], (list, tuple)):\n",
    "        for line in state['grid_wire']:\n",
    "            line.remove()\n",
    "    else:\n",
    "        state['grid_wire'].remove() # Remove last line\n",
    "    state['grid_wire'] = ax.plot_wireframe(new_gpos[0], new_gpos[1], new_gpos[2],\n",
    "                                            color='k', lw=0.2)\n",
    "    # Update scatter plots \n",
    "    for i, tr in enumerate(trs):\n",
    "        loc = tr.location(ttime)\n",
    "        state['scatter_plots'][i]._offsets3d = (\n",
    "            [loc[0]],\n",
    "            [loc[1]],\n",
    "            [loc[2]]\n",
    "        )\n",
    "    # Update dynamic title with current time\n",
    "    ax.set_title(f't = {ttime:.2f}s')\n",
    "    return state['scatter_plots'] + [state['grid_wire']]\n",
    "\n",
    "def generate_synth_data(micgeom, sfreq, num_samples, lx, lz):\n",
    "    nseed = 1\n",
    "    convamp = True \n",
    "    # Initialize 4 different WNoiseGenerator objects. \n",
    "    sig1 = ac.WNoiseGenerator(sample_freq=sfreq, num_samples=num_samples, seed=nseed    , rms=0.564) # 89 dB\n",
    "    sig2 = ac.WNoiseGenerator(sample_freq=sfreq, num_samples=num_samples, seed=nseed + 1, rms=0.4) # 86 dB\n",
    "    sig3 = ac.WNoiseGenerator(sample_freq=sfreq, num_samples=num_samples, seed=nseed + 2, rms=0.283) # 83 dB\n",
    "    sig4 = ac.WNoiseGenerator(sample_freq=sfreq, num_samples=num_samples, seed=nseed + 3, rms=0.2) # 80 dB\n",
    "\n",
    "    sigs = [sig1, sig2, sig3, sig4]\n",
    "\n",
    "\n",
    "    # Define source positions\n",
    "    sp1 = ( 1,  1, 0)\n",
    "    sp2 = ( 1, -1, 0)\n",
    "    sp3 = (-1, -1, 0)\n",
    "    sp4 = (-1,  1, 0)\n",
    "    \n",
    "    # helper method to create linear trajectories in reference origin of the \n",
    "    # source configuration\n",
    "    def create_trajectory(sp):\n",
    "        return ac.Trajectory(points={0:(-lx+sp[0],sp[1],lz+sp[2]),\n",
    "                                     t_pass:(lx+sp[0],sp[1],lz+sp[2])})\n",
    "       \n",
    "    source_pos = [sp1, sp2, sp3, sp4]\n",
    "\n",
    "    tr1 = create_trajectory(sp1)\n",
    "    tr2 = create_trajectory(sp2)\n",
    "    tr3 = create_trajectory(sp3)\n",
    "    tr4 = create_trajectory(sp4)\n",
    "\n",
    "    trs = [tr1, tr2, tr3, tr4]\n",
    "\n",
    "    # Create MovingPointSource instances for each noise signal\n",
    "    mps1 = ac.MovingPointSource(signal=sig1, mics=micgeom, trajectory=tr1, conv_amp=convamp)\n",
    "    mps2 = ac.MovingPointSource(signal=sig2, mics=micgeom, trajectory=tr2, conv_amp=convamp)\n",
    "    mps3 = ac.MovingPointSource(signal=sig3, mics=micgeom, trajectory=tr3, conv_amp=convamp)\n",
    "    mps4 = ac.MovingPointSource(signal=sig4, mics=micgeom, trajectory=tr4, conv_amp=convamp)\n",
    "    \n",
    "    # Color coding for sources\n",
    "    col = ['red', 'blue', 'orange', 'green']\n",
    "\n",
    "    # Create SourceMixer with all point sources\n",
    "    source_mixer = ac.SourceMixer(sources=[mps1, mps2, mps3, mps4])\n",
    "    return trs, col, source_mixer\n",
    "\n",
    "\n",
    "save_path = Path(\"./vid\")\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# generate animation for fixed focus\n",
    "def gen_ani_ff(rg, micgeom, trs, lz, col):\n",
    "    fig, ax, scatter_plots = init_animation_fixed_focus(rg, micgeom, trs, lz, col)\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig,\n",
    "        update_frame_fixed_focus,\n",
    "        frames=101,\n",
    "        interval=50,\n",
    "        blit=False,\n",
    "        fargs=(scatter_plots, trs, t_pass, ax)\n",
    "    )\n",
    "    writer = FFMpegWriter(fps=15, metadata=dict(artist='Acoular'), bitrate=1800)\n",
    "    HTML(ani.to_jshtml())\n",
    "    ani.save(save_path / \"fixed_focus.mp4\", writer=writer)\n",
    "    \n",
    "# generate animation for fixed focus\n",
    "def gen_ani_mv(rgm, tr0, trs, micgeom, t_pass, lz, col):\n",
    "    fig, ax, state = init_animation_moving_focus(\n",
    "        rgm, tr0, trs, micgeom, t_pass, lz, col\n",
    "    )\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig,\n",
    "        update_frame_moving_focus,\n",
    "        frames=101,\n",
    "        fargs=(state, rgm, tr0, trs, col, ax),\n",
    "        interval=50,\n",
    "        blit=False\n",
    "    )\n",
    "    writer = FFMpegWriter(fps=15, metadata=dict(artist='Acoular'), bitrate=1800)\n",
    "    HTML(ani.to_jshtml())\n",
    "    ani.save(save_path / \"moving_focus.mp4\", writer=writer)\n",
    "    \n",
    "def plot_maps(res, gird, block_size, sfreq):\n",
    "    nsize = int(np.ceil((np.sqrt(len(res)))))\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    for i,r in enumerate(res):\n",
    "        r0 = r.reshape(gird.shape)\n",
    "        plt.subplot(nsize, nsize, i+1)\n",
    "        mx = ac.L_p(r0.max())\n",
    "        plt.imshow(\n",
    "            ac.L_p(np.transpose(r0)), vmax=mx, vmin=mx - 15, interpolation='nearest', extent=gird.extend(), origin='lower'\n",
    "        )\n",
    "        plt.title(f\"t = {(i)*block_size/sfreq}\")\n",
    "        plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "\n",
    "Path('./cache/03').mkdir(parents=True, exist_ok=True)\n",
    "ac.config.cache_dir = './cache/03'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19a2a0-a21f-479f-99e3-ec8e227fa81c",
   "metadata": {},
   "source": [
    "<img src=\"img/DAGA_logo.png\" alt=\"DAGA Logo\" style=\"width:160px; position:absolute; top:20px; right:0px;\">\n",
    "<img src=\"img/TU-lang.png\" alt=\"TU Logo\" style=\"width:230px; position:absolute; top:0px; right:180px;\">\n",
    "\n",
    "<h1 style=\"margin-top: 180px; margin-bottom: 50px; color: #A81D1E;\">Beamforming in the time domain with moving sources</h1>\n",
    "<h3 style=\"margin-top: 50px; margin-bottom: 100px; color: #434343;\">Mikolaj Czuchaj, Gert Herold, Adam Kujawski, Oliver Lylloff, Art J. R. Pelling, Ennes Sarradj</h3>\n",
    "\n",
    "<h5 style=\"margin-top: 50px; margin-bottom: 100px; color: #434343;\">Jupyter Notebook available at <a href=\"https://github.com/acoular/workshop_DAS-DAGA-2025\">https://github.com/acoular/workshop_DAS-DAGA-2025</a></h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a87cde-4473-476d-a51d-566ba3124a45",
   "metadata": {},
   "source": [
    "- analysis of moving sources in many possible applications, such as train, car, or airplane pass-bys\n",
    "- this notebook demonstrates the analysis of moving sources with Acoular, using fixed and moving focus time-domain beamforming, as well as the application of moving focus CLEANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fb3aa-7563-438f-a811-b1442f342e12",
   "metadata": {},
   "source": [
    "## 1. Synthetic data\n",
    "\n",
    "![Sketch](./img/sketch_moving_sources.png \"Sketch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765e86a-3929-4cb9-b5b1-3f3e90cfbcf6",
   "metadata": {},
   "source": [
    "- synthetic input data consisting of four white noise monopole acoustic sources moving in front of the array\n",
    "- lz is the distance between the plane in which the sources move and the array plane, and lx is the distance to the starting position on the x-axis\n",
    "- sources moving with a velocity v of 60 km/h\n",
    "- simulated microphone array data with a sample rate of 12800, consisting of the entire pass-by of the sources from -lx to lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2d1ad-8e74-4a29-8122-a9a061aeb7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lx = 5 # m, distance to start position on x-axis \n",
    "lz = 10 # m, distance between array and source plane\n",
    "v = 60 # km/h, source velocity\n",
    "vx_m = v/3.6 # m/s, source velocity converted to meters per second\n",
    "t_pass = 2 * lx / vx_m  # s, total pass-by duration\n",
    "sfreq = 12800 # Hz, sampling frequency\n",
    "num_samples = int(t_pass * sfreq) # total number of samples\n",
    "block_size = int(num_samples/16) # number of samples per processing block\n",
    "freq = 4000  # Hz, third-octave band used for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74176632-cf8e-4851-a713-8ea28a376d4e",
   "metadata": {},
   "source": [
    "- we use a configuration of 64 microphones as our microphone array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e29069-4d59-4642-9312-ec89fc22b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "micgeom = ac.MicGeom(file=Path(ac.__file__).parent / 'xml' / 'tub_vogel64.xml') # selected microphone geometry\n",
    "plt.scatter(micgeom.pos[0], micgeom.pos[1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac3e8d-ad0a-4c29-97e0-252f39d944a4",
   "metadata": {},
   "source": [
    "- a linear translational trajectory can be modeled using the `Trajectory` class\n",
    "- the trajectory is defined by assigning discrete time instants (keys) to sampled (x, y, z) positions along the trajectory; based on these points, a continuous trajectory is calculated\n",
    "- a linear trajectory with constant speed can be defined by specifying two points of the trajectory\n",
    "<!-- - we model our synthetic data by first defining the signal with a signal generator in the case of white noise we use WNoiseGenerator, with given sample frequency, number of samples, a seed and an rms value\n",
    "- in order to generate the sythetic data of a moving source we use the MovingPointSouce class with the previouse signal, the trajectory and microphone array geometry\n",
    "- finally we mix the four sources using the ax.SourceMixer class, and define a Cache for it so that we do not have to regenerate it -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2dfd51-b9d4-4246-ab8f-4de18e41a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory of the origin of the source configuration\n",
    "tr0 = ac.Trajectory(points={0:(-lx,0,lz),t_pass:(lx,0,lz)})\n",
    "trs, col, source_mixer = generate_synth_data(micgeom, sfreq, num_samples, lx, lz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14847789-f1f3-40c1-b873-05fd70a3cec9",
   "metadata": {},
   "source": [
    "## 2. Beamforming in the time domain with fixed focus\n",
    "\n",
    "<!-- $$\n",
    "b(t, x_g, p_m) = \\frac{1}{K_{x_g}(t)} \\sum_{m=1}^{N} w_m \\frac{p_m\\left(t + \\frac{r_{x_g m}(t)}{c}\\right)}{r_{x_g m}(t) \\left(1 - M \\cos \\left(\\theta_{x_g m}(t)\\right)\\right)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "K_{x_g}(t) = \\sum_{m=1}^{N} \\frac{w_m}{\\left[r_{x_g m}(t) \\left(1 - M \\cos \\left(\\theta_{x_g m}(t)\\right)\\right)^2\\right]^2}\n",
    "$$                 -->\n",
    "\n",
    "- beamforming in the time domain with fixed focus consists of summing the time-delayed and amplitude-modified microphone signals on a defined grid\n",
    "- here we use a rectangular grid defined by the `RectGrid` class, measuring 8 m by 4 m with an increment of 0.1 m between each grid point, resulting in a total of 81 × 41 = 3321 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a71eec-efc2-4298-936d-ff93cde3ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = ac.RectGrid(x_min=-4, x_max=4,y_min=-2, y_max=2,z=lz, increment=0.1 )\n",
    "st = ac.SteeringVector(grid=rg, mics=micgeom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you want to generate the animation\n",
    "# gen_ani_ff(rg, micgeom, trs, lz, col)\n",
    "Video(\"./vid/fixed_focus.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7057c90",
   "metadata": {},
   "source": [
    "- create processing chain for fixed focus beamforming\n",
    "<div style=\"display: flex;\">\n",
    "  <!-- Left column with two images stacked vertically -->\n",
    "  <div style=\"display: flex; flex-direction: column; margin-right: 10px;\">\n",
    "    <img src=\"./img/pipeline_01.svg\" width=\"600\" style=\"margin-bottom: 10px;\">\n",
    "  </div>\n",
    "  <!-- Right column with one image -->\n",
    "  <div>\n",
    "    <img src=\"./img/chain.png\" width=\"100\">\n",
    "  </div>\n",
    "</div>\n",
    "<img src=\"./img/pipeline_02.svg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c2cb3-14c2-4e58-96a2-a67edc802d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = ac.FiltFiltOctave(source=source_mixer, band=freq, fraction='Third octave')\n",
    "bt = ac.BeamformerTimeSq(source=fi, steer=st, r_diag=True)\n",
    "avgt = ac.Average(source=bt, num_per_average=block_size)  # 15 single images\n",
    "cacht = ac.Cache(source=avgt)  # cache to prevent recalculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a803754-b006-4318-b0f6-faf52439a01f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = ac.tools.return_result(cacht,num=1)\n",
    "plot_maps(res, rg, block_size, sfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e5d93-2a35-4493-bfe6-bd1469b06bf0",
   "metadata": {},
   "source": [
    "## 3. Beamforming in the time domain with moving focus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e5450",
   "metadata": {},
   "source": [
    "- we use a smaller rectangular grid of 4 m by 4 m with an increment of 0.1 m between each grid point, resulting in a total of 41 × 41 = 1681 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgm = ac.RectGrid(x_min=-2, x_max=2,y_min=-2, y_max=2,z=0, increment=0.1)\n",
    "st = ac.SteeringVector(grid=rgm, mics=micgeom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you want to generate the animation\n",
    "# gen_ani_mv(rgm, tr0, trs, micgeom, t_pass, lz, col)\n",
    "Video(\"./vid/moving_focus.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a3f73",
   "metadata": {},
   "source": [
    "- create processing of chain moving focus beamforming\n",
    "- use of `BeamformerTimeSqTraj` in processing chain with set `trajectory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999670d0-d239-4d8b-99ff-74bdbd5b65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = ac.FiltFiltOctave(source=source_mixer, band=freq, fraction='Third octave')\n",
    "bt = ac.BeamformerTimeSqTraj(source=fi, steer=st, trajectory=tr0, r_diag=True)\n",
    "avgt = ac.Average(source=bt, num_per_average=block_size)  # 15 single images\n",
    "cacht = ac.Cache(source=avgt)  # cache to prevent recalculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93a094-7ad1-4bb3-b44d-6ff0140d8a1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = ac.tools.return_result(cacht,num=1)\n",
    "plot_maps(res, rgm, block_size, sfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320698f9-d56e-4e85-8ba9-b0b9313e14c1",
   "metadata": {},
   "source": [
    "## 4. Beamforming with deconvolution (CLEANT) in the time domain with moving focus\n",
    "\n",
    "\n",
    "<!-- ###### **Cleant* <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0022460X18307880\">[1]</a>:  -->\n",
    "<!-- \n",
    "$$\n",
    "\\Phi^{(0)}(t, x_g) = b(t, x_g, \\{ p_m \\}),\\quad \\Gamma^{(0)}(t, x_g) = 0,\\quad p_m^{res(0)}(t) = p_m(t)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{x}_g = \\underset{x_g}{\\text{argmax}} \\left( \\int_T |\\Phi^{(i-1)}(t, x_g)|^2\\, dt \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Gamma^{(i)}(t, \\hat{x}_g) = \\Gamma^{(i-1)}(t, \\hat{x}_g) + \\gamma \\Phi^{(i-1)}(t, \\hat{x}_g)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_m^{res(i)}\\left(t + \\frac{r_{x_g m}}{c}\\right) = p_m^{res(i-1)}\\left(t + \\frac{r_{x_g m}}{c}\\right) - \\gamma \\frac{\\Phi^{(i-1)}(t, \\hat{x}_g)}{r_{\\hat{x}_g m}(t) \\left(1 - M \\cos\\left(\\theta_{\\hat{x}_g m}(t)\\right)\\right)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Phi^{(i)}(t, x_g) = b(t, x_g, \\{ p_m^{res(i)} \\})\n",
    "$$ -->\n",
    "\n",
    "- use of `BeamformerCleantSqTraj` in processing pipeline based on *CLEANT* <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0022460X18307880\">[1]  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5051d3-6c06-44da-9f73-d9e1ee690f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = ac.FiltFiltOctave(source=source_mixer, band=freq, fraction='Third octave')\n",
    "bt = ac.BeamformerCleantSqTraj(source=fi, steer=st, trajectory=tr0, conv_amp=True)\n",
    "avgt = ac.Average(source=bt, num_per_average=block_size)  # 15 single images\n",
    "cacht = ac.Cache(source=avgt)  # cache to prevent recalculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95efa838-40cd-4d79-9106-a5f6c9e9609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ac.tools.return_result(cacht,num=1)\n",
    "plot_maps(res, rgm, block_size, sfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979d4e1",
   "metadata": {},
   "source": [
    "<h2>References</h2>\n",
    "(1)</div><div class=\"csl-right-inline\" style=\"margin: 0 .4em 0 1.5em;\">Cousson, R.; Leclère, Q.; Pallas, M.-A.; Bérengier, M. A Time Domain CLEAN Approach for the Identification of Acoustic Moving Sources. <i>Journal of Sound and Vibration</i> 2019, <i>443</i>, 47–62. <a href=\"https://doi.org/10.1016/j.jsv.2018.11.026\">https://doi.org/10.1016/j.jsv.2018.11.026</a>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d22fec",
   "metadata": {},
   "source": [
    "## Acoular Future Directions Survey – Don't forget to participate! \n",
    "\n",
    "<img src=\"img/survey.png\" alt=\"Survey\" style=\"height: auto; width: 50%;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
